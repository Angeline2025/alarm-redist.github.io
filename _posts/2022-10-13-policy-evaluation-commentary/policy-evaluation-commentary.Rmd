---
title: "The Essential Role of Policy Evaluation for the 2020 Census Disclousre Avoidance System"
description: |
  A short description of the post.
author:
    - name: Christopher T. Kenny
      affiliation: Department of Government, Harvard University
      location: Cambridge, MA
      email: christopherkenny@fas.harvard.edu
    - name: Shiro Kuriwaki
      affiliation: Department of Political Science, Yale University
      location: New Haven, CT
      email: shiro.kuriwaki@yale.edu
    - name: Cory McCartan
      affiliation: Department of Statistics, Harvard University
      location: Cambridge, MA
      email: cmccartan@fas.harvard.edu
    - name: Evan Rosenman
      affiliation: Harvard Data Science Initiative
      location: Cambridge, MA
      email: erosenm@fas.harvard.edu
    - name: Tyler Simko
      affiliation: Department of Government, Harvard University
      location: Cambridge, MA
      email: tsimko@g.harvard.edu
    - name: Kosuke Imai
      affiliation: Departments of Government and Statistics, Harvard University
      location: Cambridge, MA
      email: imai@harvard.edu
date: 2022-10-14
output:
  distill::distill_article:
    self_contained: false
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```



In “Differential Perspectives: Epistemic Disconnects Surrounding the US Census Bureau’s Use 
of Differential Privacy,” boyd and Sarathy argue that empirical evaluations of the Census 
Disclosure Avoidance System (DAS), including our published analysis, failed to recognize how 
the benchmark data against which the 2020 DAS was evaluated is never a ground truth of 
population counts. In this commentary, we explain why policy evaluation, which was the main 
goal of our analysis, is still meaningful without access to a perfect ground truth. We also point 
out that our evaluation leveraged features specific to the decennial Census and redistricting data, 
such as block-level population invariance under swapping and voter file racial identification, 
better approximating a comparison with the ground truth. Lastly, we show that accurate 
statistical predictions of individual race based on the Bayesian Improved Surname Geocoding, 
while not a violation of differential privacy, substantially increases the disclosure risk of private 
information the Census Bureau sought to protect. We conclude by arguing that policy makers 
must confront a key trade-off between data utility and privacy protection, and an epistemic 
disconnect alone is insufficient to explain disagreements between policy choices.


